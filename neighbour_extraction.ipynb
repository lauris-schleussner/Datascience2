{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktion der Daten:\n",
    "- basierend auf example.py werden hier Daten extrahier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finden von Occurences\n",
    "\n",
    "Aus stop_times.txt werden für jeden Stop aus stops.txt Zeilen extrahiert, in denen der stop vorkommt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_occ_numbers():\n",
    "    print(\"finding occurencies\")\n",
    "    stop_times = load_stop_times()\n",
    "    line_numbers = {k: [] for k in [i[0] for i in load_stops()]}\n",
    "    c = time.perf_counter()\n",
    "    new_list = []\n",
    "    for ind, elem in enumerate(stop_times):\n",
    "        new_list.append((elem[3], ind))\n",
    "    #new_list = sorted(new_list, key=lambda x: x[0])\n",
    "    for elem in new_list:\n",
    "        line_numbers[elem[0]].append(elem[1])\n",
    "    with open(\"lvb_auswertung/occ_numbers.json\", \"w+\") as f:\n",
    "        json.dump(line_numbers, f, indent=4)\n",
    "    print(\"found occurencies\")\n",
    "\n",
    "def load_all_occ_numbers():\n",
    "    with open(\"lvb_auswertung/occ_numbers.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finden von Nachbarn mit minimaler Transferzeit\n",
    "\n",
    "Nun finden wir für jede Occurency und jede Station heraus, welche Nachbarn und welche minimale Transferzeit sie zu einem Nachbarn hat.\n",
    "\n",
    "Zunächst benötigen wir dazu zwei Hilfsfunktionen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_sec(time):\n",
    "    time = time.replace('\"', '')\n",
    "    return 3600*int(time[0:2])+60*int(time[3:5])+int(time[6:8])\n",
    "\n",
    "def find_neighbours(stop_times, occ_numbers):\n",
    "    neighbours = []\n",
    "    neighbour_times = []\n",
    "    for occ_number in occ_numbers:\n",
    "        point = stop_times[occ_number]\n",
    "        point_arr = time_sec(stop_times[occ_number][1])\n",
    "        point_dep = time_sec(stop_times[occ_number][2])\n",
    "        if occ_number != 0:\n",
    "            before = stop_times[occ_number-1]\n",
    "            diff = point_arr-time_sec(stop_times[occ_number-1][2])\n",
    "            if before[0] == point[0]:\n",
    "                neighbour_times.append((before[3], diff))\n",
    "                neighbours.append(before[3])\n",
    "        \n",
    "        if occ_number != len(stop_times)-1:\n",
    "            after = stop_times[occ_number+1]\n",
    "            diff = time_sec(stop_times[occ_number+1][1])-point_dep\n",
    "            if after[0] == point[0]:\n",
    "                neighbour_times.append((after[3], diff))\n",
    "                neighbours.append(after[3])\n",
    "    neighbours = list(set(neighbours))\n",
    "    def min_time(neighbour):\n",
    "        min_list = [elem[1] for elem in neighbour_times if elem[0] == neighbour]\n",
    "        min_list = [elem for elem in min_list if elem != 0]\n",
    "        if len(min_list) == 0:\n",
    "            return 0\n",
    "        return min(min_list)\n",
    "    return [(\n",
    "                neighbour, min_time(neighbour)\n",
    "            ) for neighbour in neighbours]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung der Funktionen:\n",
    "\n",
    "- time_sec:\n",
    "  - Eine Zeit im Format \"hh:mm:ss\" wird in Sekunden umgerechnet\n",
    "  - Die Differenzen können einfach zwischen der arrival und departure-Zeit errechnet werden, findet eine Fahrt um Mitternacht statt, gibt es Uhrzeiten mit Stunde 24 und 25, daher kann diese Funktion für Differenzen verwendet werden.\n",
    "\n",
    "- find_neighbours: ermittelt für einen Stop alle Nachbarn mit minimaler Transferzeit\n",
    "  - Die Liste mit allen stop_times und occurency_numbers für einen Stop wird übergeben\n",
    "  - für jede occurency eines Stops wird ermittelt, welcher Stop davor und danach (before und after) angefahren wird (index davor bzw. danach falls vorhanden, gleicher Trip)\n",
    "  - zu einer Liste wird der Nachbar hinzugefügt, zu einer anderen der Nachbar und eine Zeitdifferenz\n",
    "  - zuletzt wird für jeden Nachbar die minimale Transferzeit größer als 0 extrahiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermittlung aller Nachbarn\n",
    "\n",
    "Anschließend wird die find_neighbours-Funktion für jeden Stop aus stops.txt ausgeführt, die gefundenen Nachbarn und Zeiten werden gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_neighbours():\n",
    "    print(\"loading data...\")\n",
    "    stop_ids = [i[0] for i in load_stops()]\n",
    "    stop_times = load_stop_times()\n",
    "    occ_numbers = load_all_occ_numbers()\n",
    "    all_neighbours = {}\n",
    "    print(\"finding neighbours...\")\n",
    "    #for elem in stop_ids[:1]:\n",
    "    for elem in tqdm(stop_ids):\n",
    "        all_neighbours[elem] = find_neighbours(stop_times, occ_numbers[elem])\n",
    "    with open(\"lvb_auswertung/neighbours.json\", \"w+\") as f:\n",
    "        json.dump(all_neighbours, f, indent=4)\n",
    "    print(\"finished...\")\n",
    "\n",
    "def load_all_neighbours():\n",
    "    with open(\"lvb_auswertung/neighbours.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding occurencies\n",
      "found occurencies\n",
      "loading data...\n",
      "finding neighbours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4377/4377 [00:05<00:00, 812.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    }
   ],
   "source": [
    "all_occ_numbers()\n",
    "all_neighbours()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finden indirekter Nachbarn\n",
    "- wofür werden diese Daten benötigt: räumlich nah beieinander liegende Haltestellen sollen für die Heatmap beachtet werden\n",
    "- andere Idee für die Heatmap:\n",
    "  - Nur Haltestellen mit bestimmtem Maximalabstand werden beachtet\n",
    "  - diese werden anhand von quadratischen Rastern mit der Seitenlänge als Abstand ermittelt (Stationen mit Abstand kleiner Maximalabstand müssen dann in benachbarten Kästchen liegen (beide Kästchenkoordinaten dürfen sich nur um maximal 1 unterscheiden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4377/4377 [00:00<00:00, 148434.02it/s]\n",
      "100%|██████████| 4377/4377 [00:00<00:00, 8719.49it/s]\n",
      "100%|██████████| 4377/4377 [00:23<00:00, 182.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# That is waaay to sow and doesnt seem to do the job...\n",
    "# Issue found: when we access neighbour_data[cur_neighbour] we actually sometimes load the added neighbours...\n",
    "\n",
    "from copy import deepcopy\n",
    "def indirect_neighbours(level):\n",
    "    neighbour_data = {k: [elem[0] for elem in v] for k, v in load_all_neighbours().items()}\n",
    "    new_data = {}\n",
    "    for i in range(level):\n",
    "        new_data = deepcopy(neighbour_data)\n",
    "        # loop through all stations\n",
    "        for cur_station in tqdm(neighbour_data):\n",
    "            # loop through all current neighbours of that station\n",
    "            for cur_neighbour in neighbour_data[cur_station]:\n",
    "                # loop through all neighbours of that neighbour\n",
    "                for neighbour_neighbour in neighbour_data[cur_neighbour]:\n",
    "                    if neighbour_neighbour not in new_data[cur_station]:\n",
    "                        new_data[cur_station].append(neighbour_neighbour)\n",
    "        neighbour_data = new_data\n",
    "    \n",
    "    with open(f\"lvb_auswertung/neighbours_{level}.json\", \"w+\") as f:\n",
    "        json.dump(neighbour_data, f, indent=4)\n",
    "    \n",
    "    return neighbour_data\n",
    "# bis level 3 ist es ok, level 4 habe ich nach 2.03it/s abgebrochen (progress: 35/4377, t=00:17)\n",
    "c = indirect_neighbours(3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umwandeln der Daten in einen Graphen:\n",
    "\n",
    "(kopiert von Lauris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0011073', '0011074', '0011005', '0012994', '0012992', '0013001', '0010983', '0011557', '0011558', '0013124', '0011553', '0011340', '0011338']\n",
      "780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fba6107c370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as n\n",
    "import json\n",
    "\n",
    "def load_graph():\n",
    "    # parse into weighted graph\n",
    "    with open('lvb_auswertung/neighbours.json', \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    g = n.Graph()\n",
    "\n",
    "    for key_stop_id, neighbours in data.items():\n",
    "        for neighbour_stop_id, time in neighbours:\n",
    "            g.add_edge(key_stop_id, neighbour_stop_id, weight = time)\n",
    "\n",
    "    path = n.dijkstra_path(g,\"0011073\", \"0011338\") # Leibnizstraße nach Moritzhof -> geht hier viel zu schnell, weil keine Umsteigezeiten beachtet werden, aber naja... wird schon passen (ist ja für alle Fahrten außer Direktverbindungen ähnlich verzerrt)\n",
    "    time = n.path_weight(g, path, weight = \"weight\")\n",
    "\n",
    "    print(path)\n",
    "    print(time)\n",
    "    \n",
    "    return g\n",
    "\n",
    "load_graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa5230c337cef4bdd6e6d95c6b2d48fd1b732fa14682ff39acb3d19543b6b96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
