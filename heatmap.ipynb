{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zielstellung\n",
    "\n",
    "- Mithilfe des Codes aus dieser Datei sollen verschiedene generelle Raumanalysen möglich gemacht werden\n",
    "- dabei werden für bestimmte Punkte (Geokoordinaten) bestimmte Werte ermittelt, die anschließend auf einer heatmap farblich dargestellt werden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umwandeln der Koordinaten in ein besser nutzbares Format\n",
    "\n",
    "- Die Geokoordinateni n WSG84 werden in das für Deutschland geeignete epsg:31468-Format umgewandelt\n",
    "- von nun an können sie wie Angaben in Metern betrachtet werden, insbesondere die Abstandsberechnung wird dadurch deutlich vereinfacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_coordinates():\n",
    "    from pyproj import Proj\n",
    "    data = {}\n",
    "    with open(\"gtfsmdvlvb/stops.txt\", \"r\") as f:\n",
    "        txt = [elem.split(\",\") for elem in f.read().split(\"\\n\")[1:-1]]\n",
    "    for elem in tqdm(txt):\n",
    "        #data[elem[0]] = [float(elem[-2]), float(elem[-1])]\n",
    "        data[elem[0]] = Proj('epsg:31468')(float(elem[-1]), float(elem[-2]))\n",
    "    with open(\"lvb_auswertung/coordinates.json\", \"w+\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    return data\n",
    "\n",
    "def load_coordinates():\n",
    "    with open(\"lvb_auswertung/coordinates.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def min_max():\n",
    "    data = load_coordinates()\n",
    "    x = [data[elem][0] for elem in data]\n",
    "    y = [data[elem][1] for elem in data]\n",
    "    return [(min(x), max(x)), (min(y), max(y))]\n",
    "\n",
    "# gibt Zwischenschritte zwischen Extremkoordinaten abhängig von einer Distanz für ein grid zurück\n",
    "def steps(dist):\n",
    "    m_m = min_max()\n",
    "    cur_x = m_m[0][0]\n",
    "    cur_y = m_m[1][0]\n",
    "    x_steps, y_steps = [cur_x], [cur_y]\n",
    "    while cur_x < m_m[0][1]:\n",
    "        cur_x += dist\n",
    "        x_steps.append(cur_x)\n",
    "    while cur_y < m_m[1][1]:\n",
    "        cur_y += dist\n",
    "        y_steps.append(cur_y)\n",
    "    return [x_steps, y_steps]\n",
    "\n",
    "\n",
    "def step_coords(dist):\n",
    "    steps = steps(dist)\n",
    "    \n",
    "#extract_coordinates()\n",
    "#print(min_max())\n",
    "c = steps(500)\n",
    "print(len(c[0])*len(c[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrahieren von Frequenzen an einer Haltestelle\n",
    "\n",
    "- für jede Haltestelle wird anhand der Routen in stop_times ermittelt, wie oft dort ein Verkehrsmittel hält\n",
    "\n",
    "Vereinfachungen:\n",
    "- jedes Verkehrsmittel gleich behandelt (beispielsweise nicht gewichtet anhand der Anzahl an Menschen, die in es passen würden)\n",
    "- Annahme, dass Verkehrsmittel über Tag hinweg, jeden Tag gleich oft kommen\n",
    "  - keine gravierende Vereinfachung, da wir untersuchen, welche Regionen gut ausgebaut sind, Anzahl Verkehrsmittel pro Tag scheint guter Vergleichsindikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4377/4377 [02:51<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4531101.507033625, 5691819.717443315, 1618]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from utils import load_stops, load_stop_times\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_frequencies():\n",
    "    stop_data = [stop[0] for stop in load_stops()]\n",
    "    trip_data = [stop_time[3] for stop_time in load_stop_times()]\n",
    "    #data = load_coordinates()\n",
    "    with open(\"lvb_auswertung/coordinates.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    for elem in tqdm(stop_data):\n",
    "        if len(data[elem]) == 2:\n",
    "            data[elem].append(trip_data.count(elem))\n",
    "        else:\n",
    "            data[elem][3] = trip_data.count(elem)\n",
    "    with open(\"lvb_auswertung/coordinates.json\", \"w+\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    return data\n",
    "\n",
    "c = calculate_frequencies()\n",
    "print(c[\"0000145\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finden von Haltestellendichten an einem Punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4377/4377 [01:03<00:00, 69.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# for every point, we execute this function, that gives back a value based on the distances to all other points\n",
    "# TODO: Gewichtung eines Punktes (zum Beispiel relevant für Anzahl der Verbindungen an einer Haltestelle -> könnte in die Haltestellendichte einfließen)\n",
    "def all_distances_point(coordinate, haltestellen):\n",
    "    distances = []\n",
    "    for other_coordinate in haltestellen:\n",
    "        weighting = 1 if len(other_coordinate) == 2 else other_coordinate[3-1]\n",
    "        coordinate, other_coordinate = tuple(coordinate[:2]), tuple(other_coordinate[:2])\n",
    "        #weighting = 1\n",
    "        #GD(coordinate, other_coordinate).m\n",
    "        distances.append((\n",
    "                ((coordinate[0]-other_coordinate[0])**2+(coordinate[1]-other_coordinate[1])**2)**(1/2),\n",
    "                weighting\n",
    "        ))\n",
    "        #if distances[-1][0] == 0:\n",
    "        #    distances = distances[:-1]\n",
    "    #while 0 in distances: distances.remove(0)\n",
    "    distances = [distance for distance in distances if distance[0] != 0]\n",
    "    if distances is None: return 0\n",
    "    value = sum([x[1]/x[0] for ind, x in enumerate(distances)])\n",
    "    return value\n",
    "\n",
    "# Hier müssen wir nochmal überlegen, wie wir die Punkte ausdrücken wollen (idealerweise nicht durch die Koordinaten, sondern durch stop-indizes beziehungsweise Rasterkoordinaten (ganzzahlig als Tupel bzw string im format '{x}|{y}'))\n",
    "def all_distances(points, haltestellen):\n",
    "    distances = []\n",
    "    for point in tqdm(points):\n",
    "        distances.append([point, all_distances_point(points[point], deepcopy(haltestellen))])\n",
    "    return distances\n",
    "\n",
    "def haltestellendichte(weighting=False):\n",
    "    with open(\"lvb_auswertung/coordinates.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        # without weighting\n",
    "        if not weighting:\n",
    "            coordinates = [data[elem][:2] for elem in data]\n",
    "            goal_file = \"dichte\"\n",
    "        else:\n",
    "        # with weightings by stops per day\n",
    "            coordinates = [data[elem] for elem in data]\n",
    "            goal_file = \"dichte_weighting\"\n",
    "    \n",
    "    with open(f\"lvb_auswertung/{goal_file}.json\", \"w+\") as f:\n",
    "        json.dump(all_distances(data, coordinates), f, indent=4)\n",
    "\n",
    "\n",
    "haltestellendichte()\n",
    "haltestellendichte(weighting=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa5230c337cef4bdd6e6d95c6b2d48fd1b732fa14682ff39acb3d19543b6b96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
